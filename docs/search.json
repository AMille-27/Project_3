[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA file",
    "section": "",
    "text": "This project uses the 2015 BRFSS Diabetes Health Indicators data set. This page will be an exploration of the predictors physical health, Education, and health care coverage impact on the response Diabetes_binary, which identifies whether a person has diabetes or not. These variables were chosen based on their potential relationship to diabetes risk, as explore in this EDA. I want to later be able to model/predict the prevalence of diabetes with based on these variables/predictors."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA file",
    "section": "",
    "text": "This project uses the 2015 BRFSS Diabetes Health Indicators data set. This page will be an exploration of the predictors physical health, Education, and health care coverage impact on the response Diabetes_binary, which identifies whether a person has diabetes or not. These variables were chosen based on their potential relationship to diabetes risk, as explore in this EDA. I want to later be able to model/predict the prevalence of diabetes with based on these variables/predictors."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "EDA file",
    "section": "Data",
    "text": "Data\n\nlibrary(readr)\n\ndiabetes_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.5.1\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nEDA_diabetes_data &lt;- diabetes_data |&gt;\n  select(Diabetes_binary, AnyHealthcare, Education, PhysActivity, PhysHlth, HighBP, HighChol,CholCheck,Smoker,Stroke, HeartDiseaseorAttack, Fruits, Veggies, HvyAlcoholConsump, NoDocbcCost, GenHlth, Sex, Income, BMI, MentHlth, DiffWalk)\n  \nEDA_diabetes_data&lt;- EDA_diabetes_data |&gt; mutate(Education_fac = factor(Education, levels = 1:6, \nlabels = c(\"None\", \"Elementary\", \"Some_HS\", \"HS_Grad\",\"Some_College\", \"College_Grad\")),\nHealth_Care_Coverage = factor(AnyHealthcare,\n  levels = c(1,0),\n  labels = c(\"Yes\", \"No\")),\nDiabetes_binary_fac = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\nPhysActivity= factor(PhysActivity, levels = c(0,1),\nlabels = c( \"No\", \"Yes\")),\nHighChol= factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nHighBP= factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nCholCheck= factor(CholCheck, levels = c(0,1), labels = c(\"No chk in 5 yrs\", \"Yes chk in 5 yrs\")),\nSmoker= factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nFruits= factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nVeggies= factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nHvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nNoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\nGenHlth= factor(GenHlth, levels = c(1:5), labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")), \nSex= factor(Sex, levels = c(0,1), labels = c(\"Male\", \"Female\")),\nIncome = factor(Income, levels = c(1:8), labels = c(\"less than $10k\", \"$10k-$15k\", \"$15k-$20K\", \"$20K-$25K\", \"$25K-$35K\",\"$35K-$50K\", \"$50K-$75K\", \"$75k or more\")), \nStroke = factor(Stroke, levels = c(0, 1), labels = c(\"No\",\"Yes\")),\nHeartDiseaseorAttack= factor(HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\",\"Yes\")),\nDiffWalk = factor(DiffWalk, levels = c(0, 1), labels = c(\"No\",\"Yes\"))\n)\n\n\nBar graph of Education Vs Diabetes Binary\nHere I want to visualize the levels of educations and diabetes. What do the different levels of education and amount of diabetes look like? Is there one group that has a particular higher or lower amount?\n\nlibrary(ggplot2)\n\nggplot(EDA_diabetes_data, aes(Education_fac, fill= Diabetes_binary_fac))+\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Diabetes Status by Education Level\",\n    x= \"Education Level\",\n    y= \"Proportion\", \n    fill = \"Has Diabetes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom a preliminary glance, it appears that people who did not attend school or only completed up to the eighth grader are more likely to have diabetes. And the trend seems to go down as the education level increases. This might suggest that higher education may be associated with lower diabetes prevalence. Or there could be some socio-economic coincidences that go along with education level. More investigation is needed.\n\n\nHealth Care Coverage and Diabetes_binary\nHere, I wanted to see if there was a hint of a relationship between access to health care coverage and the diabetes.\n\nggplot(EDA_diabetes_data, aes(x= Health_Care_Coverage, fill = Diabetes_binary_fac)) + \n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Status and Health Care Coverage\",\n    y= \"Count\", \n    fill = \"Has Diabetes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis one was interesting because before I ran the data display, I thought there was variation and it was none. All of the people sampled had some form of insurance. This raised more questions than answers.At first I thought I did something wrong and then I ran a simple count function revealing that all 241,263 people have health care coverage. This metric might not be as useful as I had initially hoped. I wonder what happened to the people that do not have health care coverage? Upon graphing I have the graph that is now displayed. There is a significantly greater amount of people with health care coverage than no coverage. And more than half of the people with coverage do not have diabetes. The people who are not covered a small amount have diabetes.\n\n\nPhysical Health and Diabetes\nHere is a histogram of amount of poor physical health in the past 30 days. There is a lot of people who did not have poor phyiscal health, while only a few had poor physical health all 30 days.\n\nggplot(EDA_diabetes_data, aes(x= PhysHlth)) + geom_histogram(binwidth = 2, fill = \"blue\", color = \"white\") + \n  labs(\n    title = \"Days of Poor Phyiscal Health\",\n    x= \"Days of 30\" ,\n    y= \"Count\" ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBox Plot of Exercise and Diabetes. I think this will show a better picture of the distribution.\n\nggplot(EDA_diabetes_data, aes(x = Diabetes_binary_fac, y= PhysHlth, fill = Diabetes_binary_fac)) +\n  geom_boxplot()+\n  labs(\n    title = \"Poor Physical Health Days by Diabetes Status\", \n    x= \"Has Diabetes\", \n    y= \"Days of Poor Phyiscal Health\",\n    fill = \"Has Diabetes\"\n  )+\n  theme_classic()\n\n\n\n\n\n\n\n\nThis is a much better visualization of poor physical health and diabetes. The median for poor physical health days for people with diabetes appears to be slightly higher than the people without diabetes. Both distributions are skewed to the right, meaning most people report fewer days of poor health. This could be something that could be looked into further The spread of people who have diabetes is higher than the people who do not have diabetes.There are a lot of outliers for people who do not have diabetes. This data display might suggest that people with diabetes might have less good physical health days than people without, but there is also great variability within the group with diabetes. This means some people report numerous bad health days while others simply did not. This means more investigation is needed.\nBelow are to aid in getting default values for the API.\n\ntable(EDA_diabetes_data$Education_fac)\n\n\n        None   Elementary      Some_HS      HS_Grad Some_College College_Grad \n         174         4043         9478        62750        69910       107325 \n\ntable(EDA_diabetes_data$Fruits)\n\n\n    No    Yes \n 92782 160898 \n\ntable(EDA_diabetes_data$Income)\n\n\nless than $10k      $10k-$15k      $15k-$20K      $20K-$25K      $25K-$35K \n          9811          11783          15994          20135          25883 \n     $35K-$50K      $50K-$75K   $75k or more \n         36470          43219          90385 \n\nmean(EDA_diabetes_data$PhysHlth)\n\n[1] 4.242081\n\ntable(EDA_diabetes_data$Health_Care_Coverage)\n\n\n   Yes     No \n241263  12417 \n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "Model File.html",
    "href": "Model File.html",
    "title": "Modeling File",
    "section": "",
    "text": "This project uses the 2015 BRFSS Diabetes Health Indicators data set. We will explore and model Diabetes_binary (yes or no to having diabetes) using several predictors.\n\nsuppressPackageStartupMessages(library(caret))\n\nWarning: package 'caret' was built under R version 4.5.1\n\nsuppressPackageStartupMessages(library(tidyverse))\n\nWarning: package 'tidyverse' was built under R version 4.5.1\n\n\nWarning: package 'purrr' was built under R version 4.5.1\n\n\nWarning: package 'dplyr' was built under R version 4.5.1\n\nsuppressPackageStartupMessages(library(tidymodels))\n\nWarning: package 'tidymodels' was built under R version 4.5.1\n\n\nWarning: package 'dials' was built under R version 4.5.1\n\n\nWarning: package 'infer' was built under R version 4.5.1\n\n\nWarning: package 'modeldata' was built under R version 4.5.1\n\n\nWarning: package 'parsnip' was built under R version 4.5.1\n\n\nWarning: package 'recipes' was built under R version 4.5.1\n\n\nWarning: package 'rsample' was built under R version 4.5.1\n\n\nWarning: package 'tune' was built under R version 4.5.1\n\n\nWarning: package 'workflows' was built under R version 4.5.1\n\n\nWarning: package 'workflowsets' was built under R version 4.5.1\n\n\nWarning: package 'yardstick' was built under R version 4.5.1\n\nsource(\"transferable_EDA_for_Model.R\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nset.seed(22)\ndiabetes_data_split &lt;- initial_split(EDA_diabetes_data, prop = 0.70) \ndiabetes_data_training &lt;-training (diabetes_data_split) \ndiabetes_data_test &lt;-testing (diabetes_data_split) \ndiabetes_CV_folds &lt;- vfold_cv(diabetes_data_training, 5)"
  },
  {
    "objectID": "Model File.html#introduction",
    "href": "Model File.html#introduction",
    "title": "Modeling File",
    "section": "",
    "text": "This project uses the 2015 BRFSS Diabetes Health Indicators data set. We will explore and model Diabetes_binary (yes or no to having diabetes) using several predictors.\n\nsuppressPackageStartupMessages(library(caret))\n\nWarning: package 'caret' was built under R version 4.5.1\n\nsuppressPackageStartupMessages(library(tidyverse))\n\nWarning: package 'tidyverse' was built under R version 4.5.1\n\n\nWarning: package 'purrr' was built under R version 4.5.1\n\n\nWarning: package 'dplyr' was built under R version 4.5.1\n\nsuppressPackageStartupMessages(library(tidymodels))\n\nWarning: package 'tidymodels' was built under R version 4.5.1\n\n\nWarning: package 'dials' was built under R version 4.5.1\n\n\nWarning: package 'infer' was built under R version 4.5.1\n\n\nWarning: package 'modeldata' was built under R version 4.5.1\n\n\nWarning: package 'parsnip' was built under R version 4.5.1\n\n\nWarning: package 'recipes' was built under R version 4.5.1\n\n\nWarning: package 'rsample' was built under R version 4.5.1\n\n\nWarning: package 'tune' was built under R version 4.5.1\n\n\nWarning: package 'workflows' was built under R version 4.5.1\n\n\nWarning: package 'workflowsets' was built under R version 4.5.1\n\n\nWarning: package 'yardstick' was built under R version 4.5.1\n\nsource(\"transferable_EDA_for_Model.R\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nset.seed(22)\ndiabetes_data_split &lt;- initial_split(EDA_diabetes_data, prop = 0.70) \ndiabetes_data_training &lt;-training (diabetes_data_split) \ndiabetes_data_test &lt;-testing (diabetes_data_split) \ndiabetes_CV_folds &lt;- vfold_cv(diabetes_data_training, 5)"
  },
  {
    "objectID": "Model File.html#logistic-regression-models",
    "href": "Model File.html#logistic-regression-models",
    "title": "Modeling File",
    "section": "Logistic Regression Models",
    "text": "Logistic Regression Models\n\nExplanation\nA logistic model is a model that can use both categorical and numeric variables, and we use it to gauge the likelihood of a binary response happening. This could be something that would be yes or no, true or false kind of variable. In this case we use it to predict the likelihood of someone having diabetes, based on the variables below. A linear model would not work here because of the type of variables being used. Now we will create a few logistic models for the response Diabetes_binary, whether someone has diabetes or not. The first model will be based on education level, and physical health. Model 2 will be based on education level, physical health, Any healthcare coverage and income. Model 3 will be based on education level, physical health, Any healthcare coverage,income, fruit consumption.\n\nLR1_recipe &lt;- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth, data = diabetes_data_training ) |&gt;\n  step_normalize(PhysHlth)\nLR2_recipe &lt;- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage + Income, data = diabetes_data_training ) |&gt;\n  step_normalize(PhysHlth)\nLR3_recipe &lt;-recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage + Income + Fruits, data = diabetes_data_training ) |&gt;\n  step_normalize(PhysHlth)\n\nLR_spec &lt;- logistic_reg() |&gt;\n  set_engine(\"glm\")\nLR1_wkf &lt;-workflow() |&gt;\n  add_recipe(LR1_recipe) |&gt;\n  add_model(LR_spec)\nLR2_wkf &lt;-workflow() |&gt;\n  add_recipe(LR2_recipe) |&gt;\n  add_model(LR_spec)\nLR3_wkf &lt;-workflow() |&gt;\n  add_recipe(LR3_recipe) |&gt;\n  add_model(LR_spec)\n \n LR1_fit &lt;- LR1_wkf |&gt;\n  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))\n LR2_fit &lt;- LR2_wkf |&gt;\n  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))\n LR3_fit &lt;- LR3_wkf |&gt;\n  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))\n \nLR_metrics &lt;-rbind(LR1_fit |&gt; collect_metrics(),\n      LR2_fit |&gt; collect_metrics(),\n      LR3_fit |&gt; collect_metrics()) |&gt;\n  mutate(Model = c(\"Model1\", \"Model1\", \"Model2\", \"Model2\", \"Model3\", \"Model3\")) |&gt;\n  select(Model, everything())\n\nLR_metrics\n\n# A tibble: 6 × 7\n  Model  .metric     .estimator  mean     n  std_err .config             \n  &lt;chr&gt;  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 Model1 accuracy    binary     0.861     5 0.000934 Preprocessor1_Model1\n2 Model1 mn_log_loss binary     0.386     5 0.00190  Preprocessor1_Model1\n3 Model2 accuracy    binary     0.861     5 0.000957 Preprocessor1_Model1\n4 Model2 mn_log_loss binary     0.381     5 0.00186  Preprocessor1_Model1\n5 Model3 accuracy    binary     0.861     5 0.000929 Preprocessor1_Model1\n6 Model3 mn_log_loss binary     0.380     5 0.00188  Preprocessor1_Model1\n\n\n\n\nResults/Choice\nAccording to the Logistic Regression that I just ran Model 3 would be the best because it has a lower log-loss. But Model 2 is very close behind if we only keep 3 or 4 decimals they would be approximately the same."
  },
  {
    "objectID": "Model File.html#classification-tree",
    "href": "Model File.html#classification-tree",
    "title": "Modeling File",
    "section": "Classification tree",
    "text": "Classification tree\nA classification tree is a type of decision tree where the response variable is categorical, binary. In our case subject has diabetes yes or no. It works by using certain rules to repeatedly split the training data into smaller sections. Each time the data is split a new branch is made. This process is continued until certain conditions are met based on the rule the machine is using. To make it so the tree wouldn’t grow too large and overfitting the training set we use a cost_complexity parameter. One can use a classification tree if they want an easy to interpret visual representation of the decision making process. Classification trees can be used if the response variable is categorical, binary. For this I used Level of education, number of poor physical health days in the a month, and health care coverage as the predictors for having diabetes or not.\n\ntrain_tree &lt;- diabetes_data_training |&gt;\n  select(-Diabetes_binary, -AnyHealthcare, -Education)\ntest_tree &lt;-diabetes_data_test |&gt;\n  select(-Diabetes_binary, -AnyHealthcare, -Education)\n\ntree_rec &lt;- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage, data = train_tree)\n\ntree_rec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 3\n\ntree_mod &lt;- decision_tree( tree_depth = tune(),\n min_n = 20, \n cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\ntree_wkf &lt;-workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\ntree_grid &lt;- grid_regular(cost_complexity(),\ntree_depth(),\nlevels = c(10, 5))\n\nmy_metrics &lt;- metric_set(accuracy, roc_auc, brier_class, mn_log_loss)\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = diabetes_CV_folds,\n                grid = tree_grid,\n            metrics = my_metrics)\ntree_fits\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics           .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;             &lt;list&gt;          \n1 &lt;split [142060/35516]&gt; Fold1 &lt;tibble [200 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142061/35515]&gt; Fold2 &lt;tibble [200 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142061/35515]&gt; Fold3 &lt;tibble [200 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142061/35515]&gt; Fold4 &lt;tibble [200 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142061/35515]&gt; Fold5 &lt;tibble [200 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 200 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 accuracy    binary     0.861     5 9.36e-4 Prepro…\n 2    0.0000000001          1 brier_class binary     0.120     5 6.76e-4 Prepro…\n 3    0.0000000001          1 mn_log_loss binary     0.403     5 1.71e-3 Prepro…\n 4    0.0000000001          1 roc_auc     binary     0.5       5 0       Prepro…\n 5    0.000000001           1 accuracy    binary     0.861     5 9.36e-4 Prepro…\n 6    0.000000001           1 brier_class binary     0.120     5 6.76e-4 Prepro…\n 7    0.000000001           1 mn_log_loss binary     0.403     5 1.71e-3 Prepro…\n 8    0.000000001           1 roc_auc     binary     0.5       5 0       Prepro…\n 9    0.00000001            1 accuracy    binary     0.861     5 9.36e-4 Prepro…\n10    0.00000001            1 brier_class binary     0.120     5 6.76e-4 Prepro…\n# ℹ 190 more rows\n\ntree_fits %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001         11 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 2    0.000000001          11 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 3    0.00000001           11 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 4    0.0000001            11 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 5    0.000001             11 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 6    0.0000000001         15 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 7    0.000000001          15 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 8    0.00000001           15 mn_log_loss binary     0.389     5 0.00269 Prepro…\n 9    0.0000001            15 mn_log_loss binary     0.389     5 0.00269 Prepro…\n10    0.000001             15 mn_log_loss binary     0.389     5 0.00269 Prepro…\n# ℹ 40 more rows\n\ntree_best_params &lt;- select_best(tree_fits, metric = \"mn_log_loss\")\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001         11 Preprocessor1_Model31\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(diabetes_data_split)\n\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177576/76104]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 roc_auc     binary         0.584 Preprocessor1_Model1\n3 brier_class binary         0.117 Preprocessor1_Model1\n\ntree_final_model &lt;- extract_workflow(tree_final_fit) \ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 177576 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 177576 24691 No (0.8609553 0.1390447)  \n     2) PhysHlth&lt; 7.5 148926 16928 No (0.8863328 0.1136672) *\n     3) PhysHlth&gt;=7.5 28650  7763 No (0.7290401 0.2709599)  \n       6) Education_fac=Some_College,College_Grad 16575  4007 No (0.7582504 0.2417496) *\n       7) Education_fac=None,Elementary,Some_HS,HS_Grad 12075  3756 No (0.6889441 0.3110559)  \n        14) Education_fac=HS_Grad 9009  2652 No (0.7056277 0.2943723) *\n        15) Education_fac=None,Elementary,Some_HS 3066  1104 No (0.6399217 0.3600783)  \n          30) Health_Care_Coverage=No 321    77 No (0.7601246 0.2398754) *\n          31) Health_Care_Coverage=Yes 2745  1027 No (0.6258652 0.3741348)  \n            62) Education_fac=None,Some_HS 1913   681 No (0.6440146 0.3559854) *\n            63) Education_fac=Elementary 832   346 No (0.5841346 0.4158654)  \n             126) PhysHlth&lt; 16.5 232    82 No (0.6465517 0.3534483)  \n               252) PhysHlth&gt;=12.5 121    38 No (0.6859504 0.3140496) *\n               253) PhysHlth&lt; 12.5 111    44 No (0.6036036 0.3963964)  \n                 506) PhysHlth&lt; 8.5 18     5 No (0.7222222 0.2777778) *\n                 507) PhysHlth&gt;=8.5 93    39 No (0.5806452 0.4193548)  \n                  1014) PhysHlth&lt; 11 82    33 No (0.5975610 0.4024390) *\n                  1015) PhysHlth&gt;=11 11     5 Yes (0.4545455 0.5454545) *\n             127) PhysHlth&gt;=16.5 600   264 No (0.5600000 0.4400000)  \n               254) PhysHlth&gt;=24.5 504   213 No (0.5773810 0.4226190) *\n               255) PhysHlth&lt; 24.5 96    45 Yes (0.4687500 0.5312500) *\n\ntree_final_model %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\n\nResults\nThe tree begins by asking if a person has had less than 7.5 days of poor physical health. If the answer is yes, we go left, and if the answer is no, we go right. The left side predicts no diabetes, with 84% of all observations that took this path resulting in no diabetes. And the tree continues for people who had more than 7.5 days of poor health days to ask Education level: some college/college grad. If yes, we again go to the left, and if no, then to the right, and the tree continues. The left side means that of all the observations that had some college/college grad 9% were predicted not to have diabetes. The tree goes on to split into education level high school grad, Health care coverage, education level none/some high school, poor physical health days less than 17, poor physical health days greater than or equal to 13, poor physical health days less than 8.5, poor physical health days less than 11, and lastly poor physical health days greater than or equal to 25."
  },
  {
    "objectID": "Model File.html#random-forest",
    "href": "Model File.html#random-forest",
    "title": "Modeling File",
    "section": "Random Forest",
    "text": "Random Forest\n\nExplanation\nA Random Forest is a type of ensemble tree that creates multiple trees from bootstrap samples. Each tree is trained on a small sample size of predictors in an effort to reduce overfitting. So it makes a tree diagram, gets the results of that tree using the training data, and then it repeats the process as many times as required. Then it averages the results in some way for a final prediction. Random forest could be used if you are not interested in testing all of the predictors, but you do have a mix of categorical and quantitative variables. Random forest should also be considered if you are less concerned about the interpretation of individual predictors.\n\nsuppressPackageStartupMessages(library(parsnip))\nsuppressPackageStartupMessages(library(rpart))\nsuppressPackageStartupMessages(library(ranger))\n\nWarning: package 'ranger' was built under R version 4.5.1\n\nrf_spec &lt;- rand_forest(mtry = tune(), trees = 800, min_n = 20) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(rf_spec)\n\nrf_fit &lt;-rf_wkf |&gt;\n  tune_grid(\n    resamples = diabetes_CV_folds,\n    grid = 4, \n    metrics = my_metrics)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrf_fit |&gt;\n  collect_metrics() |&gt; \n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 3 × 7\n   mtry .metric     .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     2 mn_log_loss binary     0.384     5 0.00191 Preprocessor1_Model1\n2     3 mn_log_loss binary     0.385     5 0.00205 Preprocessor1_Model3\n3     1 mn_log_loss binary     0.386     5 0.00171 Preprocessor1_Model2\n\nrf_best_params &lt;- select_best(rf_fit, metric =\"mn_log_loss\")\n\nrf_final_wk &lt;- finalize_workflow(rf_wkf, rf_best_params)\n\nrf_final_fit &lt;- rf_final_wk |&gt;\n  last_fit(diabetes_data_split, metrics = metric_set(accuracy, mn_log_loss))\n\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 mn_log_loss binary         0.387 Preprocessor1_Model1\n\n\n\n\nResults\nAfter fitting the random forest model, I tuned with mtry and min_n. I collected the metrics of accuracy and log loss. The best model had an mtry of 2 with a log loss of 0.384."
  },
  {
    "objectID": "Model File.html#final-model-selection",
    "href": "Model File.html#final-model-selection",
    "title": "Modeling File",
    "section": "Final Model Selection",
    "text": "Final Model Selection\n\nLogistic Regression Model\nBelow is the testing of the third Logistic Regression model.\n\n LR3_wkf |&gt; \n  last_fit(diabetes_data_split,\n                     metrics = metric_set(accuracy, mn_log_loss)) |&gt; \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 mn_log_loss binary         0.383 Preprocessor1_Model1\n\n\nThe log loss on the test data set is 0.383, while the log loss on the trained data was 0.380. This shows that the model was consistent in predicting the test set. We should be good to use it on other unused data.\n\n\nClassification Tree\nI already ran the prediction on the test set above for the Classification Tree, but here it is again.\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(diabetes_data_split, metrics = my_metrics)\n\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177576/76104]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 4 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 roc_auc     binary         0.584 Preprocessor1_Model1\n3 brier_class binary         0.117 Preprocessor1_Model1\n4 mn_log_loss binary         0.394 Preprocessor1_Model1\n\ntree_final_model &lt;- extract_workflow(tree_final_fit) \ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 177576 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 177576 24691 No (0.8609553 0.1390447)  \n     2) PhysHlth&lt; 7.5 148926 16928 No (0.8863328 0.1136672) *\n     3) PhysHlth&gt;=7.5 28650  7763 No (0.7290401 0.2709599)  \n       6) Education_fac=Some_College,College_Grad 16575  4007 No (0.7582504 0.2417496) *\n       7) Education_fac=None,Elementary,Some_HS,HS_Grad 12075  3756 No (0.6889441 0.3110559)  \n        14) Education_fac=HS_Grad 9009  2652 No (0.7056277 0.2943723) *\n        15) Education_fac=None,Elementary,Some_HS 3066  1104 No (0.6399217 0.3600783)  \n          30) Health_Care_Coverage=No 321    77 No (0.7601246 0.2398754) *\n          31) Health_Care_Coverage=Yes 2745  1027 No (0.6258652 0.3741348)  \n            62) Education_fac=None,Some_HS 1913   681 No (0.6440146 0.3559854) *\n            63) Education_fac=Elementary 832   346 No (0.5841346 0.4158654)  \n             126) PhysHlth&lt; 16.5 232    82 No (0.6465517 0.3534483)  \n               252) PhysHlth&gt;=12.5 121    38 No (0.6859504 0.3140496) *\n               253) PhysHlth&lt; 12.5 111    44 No (0.6036036 0.3963964)  \n                 506) PhysHlth&lt; 8.5 18     5 No (0.7222222 0.2777778) *\n                 507) PhysHlth&gt;=8.5 93    39 No (0.5806452 0.4193548)  \n                  1014) PhysHlth&lt; 11 82    33 No (0.5975610 0.4024390) *\n                  1015) PhysHlth&gt;=11 11     5 Yes (0.4545455 0.5454545) *\n             127) PhysHlth&gt;=16.5 600   264 No (0.5600000 0.4400000)  \n               254) PhysHlth&gt;=24.5 504   213 No (0.5773810 0.4226190) *\n               255) PhysHlth&lt; 24.5 96    45 Yes (0.4687500 0.5312500) *\n\ntree_final_model %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\nThe log loss for the trained data was 0.389 and the log loss for the tested set was 0.394. It seems that the model was pretty consistent in predicting the on the test data. I will note that the 0.394 is slightly less confident.\n\n\nRandom Forest\nI already ran the prediction on the test set above for the Random Forest model, but here it is again.\n\nrf_final_fit &lt;- rf_final_wk |&gt;\n  last_fit(diabetes_data_split, metrics = metric_set(accuracy, mn_log_loss))\n\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 mn_log_loss binary         0.387 Preprocessor1_Model1\n\n\nThis shows that when the best model from the trained set is now used on the tested set the log loss is 0.387 and the accuracy is 0.860 while the trained data set had a log loss of 0.384. These numbers align with the results of the training set. I would move to say this is a good model.\n\n\nThe WINNER\nThis is a tough to decide. The winner I choose is Logistic Regression model. Here are the things I considered while making this decision. Random Forest model training and test set log loss are only 0.003 from each other, but interpreting the model could prove to be challenging. But Random Forest tend to be highly accurate models. And from this project experience they tend to take more time. While interpreting the classification tree is easier, the log loss metrics for the test and training are the furthest away from each other at 0.005. And classification trees tend to be less accurate models. Logistic Regression model training and test sets log losses are also 0.003 from each other. But logistic regression do not work well with non linear data. Looking at another metric, accuracy on the test set, both Classification Tree and Logistic regression model have an accuracy of 0.860. To no surprise Random Forest has a higher accuracy of 0.865.\nClick here to return to EDA Page"
  }
]