---
title: "Modeling File"
author: "Alise Miller"
format: html
editor: visual
---

## Introduction

This project uses the 2015 BRFSS Diabetes Health Indicators data set. We will explore and model Diabetes_binary (yes or no to having diabetes) using several predictors.

```{r}
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))


set.seed(22)
diabetes_data_split <- initial_split(EDA_diabetes_data, prop = 0.70) 
diabetes_data_training <-training (diabetes_data_split) 
diabetes_data_test <-testing (diabetes_data_split) 
diabetes_CV_folds <- vfold_cv(diabetes_data_training, 5)


```

## Logistic Regression Models

### Explanation

A logistic model is a model that can use both categorical and numeric variables, and we use it to gauge the likelihood of a binary response happening. This could be something that would be yes or no, true or false kind of variable. In this case we use it to predict the likelihood of someone having diabetes, based on the variables below. A linear model would not work here because of the type of variables being used. Now we will create a few logistic models for the response Diabetes_binary, whether someone has diabetes or not. The first model will be based on education level, and physical health. Model 2 will be based on education level, physical health, Any healthcare coverage and income. Model 3 will be based on education level, physical health, Any healthcare coverage,income, fruit consumption.

```{r}
LR1_recipe <- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth, data = diabetes_data_training ) |>
  step_normalize(PhysHlth)
LR2_recipe <- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage + Income, data = diabetes_data_training ) |>
  step_normalize(PhysHlth)
LR3_recipe <-recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage + Income + Fruits, data = diabetes_data_training ) |>
  step_normalize(PhysHlth)

LR_spec <- logistic_reg() |>
  set_engine("glm")
LR1_wkf <-workflow() |>
  add_recipe(LR1_recipe) |>
  add_model(LR_spec)
LR2_wkf <-workflow() |>
  add_recipe(LR2_recipe) |>
  add_model(LR_spec)
LR3_wkf <-workflow() |>
  add_recipe(LR3_recipe) |>
  add_model(LR_spec)
 
 LR1_fit <- LR1_wkf |>
  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
 LR2_fit <- LR2_wkf |>
  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
 LR3_fit <- LR3_wkf |>
  fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
 
LR_metrics <-rbind(LR1_fit |> collect_metrics(),
      LR2_fit |> collect_metrics(),
      LR3_fit |> collect_metrics()) |>
  mutate(Model = c("Model1", "Model1", "Model2", "Model2", "Model3", "Model3")) |>
  select(Model, everything())

LR_metrics
```

### Results/Choice

According to the Logistic Regression that I just ran Model 3 would be the best because it has a lower log-loss. But Model 2 is very close behind if we only keep 3 or 4 decimals they would be approximately the same.

## Classification tree

A classification tree is a type of decision tree when the response variable is categorical, binary. In our case subject has diabetes yes or no. It works by using certain rules to repeatedly split the training data into smaller sections. Each time the data is split a new branch is made. This process is continued until certain conditions are met based on the rule the machine is using. To make it so the tree wouldn't grow too large and overfitting the training set we use a cost_complexity parameter.  One can use a classification tree if they want an easy to interpret visual representation of the decision making process. Classification trees can be used if the response variable is categorical, binary. For this I used Level of education, number of poor physical health days in the a month, and health care coverage as the predictors for having diabetes or not. 

```{r}

train_tree <- diabetes_data_training |>
  select(-Diabetes_binary, -AnyHealthcare, -Education)
test_tree <-diabetes_data_test |>
  select(-Diabetes_binary, -AnyHealthcare, -Education)

tree_rec <- recipe(Diabetes_binary_fac ~ Education_fac + PhysHlth + Health_Care_Coverage, data = train_tree)

tree_rec

tree_mod <- decision_tree( tree_depth = tune(),
 min_n = 20, 
 cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

tree_wkf <-workflow() |>
  add_recipe(tree_rec) |>
  add_model(tree_mod)

tree_grid <- grid_regular(cost_complexity(),
tree_depth(),
levels = c(10, 5))

my_metrics <- metric_set(accuracy, roc_auc, brier_class, mn_log_loss)

tree_fits <- tree_wkf |> 
  tune_grid(resamples = diabetes_CV_folds,
                grid = tree_grid,
            metrics = my_metrics)
tree_fits

tree_fits |>
  collect_metrics()

tree_fits %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)

tree_fits |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)
tree_best_params <- select_best(tree_fits, metric = "mn_log_loss")

tree_best_params

tree_final_wkf <- tree_wkf |>
  finalize_workflow(tree_best_params)

tree_final_fit <- tree_final_wkf |>
  last_fit(diabetes_data_split)

tree_final_fit

tree_final_fit |>
  collect_metrics()

tree_final_model <- extract_workflow(tree_final_fit) 
tree_final_model

tree_final_model %>%
  extract_fit_engine() %>%
  rpart.plot::rpart.plot(roundint = FALSE)
```

### Results

The tree starts off by asking if a person has less than 7.5 days of poor physical health. If the answer is yes we go left and if the answer is no we go right. The left sides predicts no diabetes, with 84% of all observations that took this path resulted in no diabetes. And the tree continues for people who had more than 7.5 days of poor health days to ask Education level: some college/college grad. If yes we again go to the left and if no then to the right and the tree continues. The left side means of all the observation that had some college/college grad 9% were predicted to not have diabetes. The tree goes on to split into education level high school grad, Health care coverage, education level none/some high school, poor physical health days less than 17,  poor physical health days greater than or equal to 13, poor physical health days less than 8.5,  poor physical health days less than 11, and lastly  poor physical health days greater than or equal to 25. 

## Random Forest

### Explanation
A Random Forest is a type of ensemble tree that  creates multiple trees from bootstrap samples. Each tree is trained on a small sample size of predictors in hopes to reduce overfitting. So it makes a tree diagram gets the results of that tree using the training data, then it repeats the process as many times as required. Then it averages results in some way for a final prediction. Random forest could be used if you are not interested in testing all of the predictors but you do have a mix of categorical and quantitative variables. Random forest should also be considered if you are less concerned about interpretation of individual predictors. 

```{r}
suppressPackageStartupMessages(library(parsnip))
suppressPackageStartupMessages(library(rpart))
suppressPackageStartupMessages(library(ranger))


rf_spec <- rand_forest(mtry = tune(), trees = 800, min_n = 20) |>
  set_engine("ranger") |>
  set_mode("classification")

rf_wkf <- workflow() |>
  add_recipe(tree_rec) |>
  add_model(rf_spec)

rf_fit <-rf_wkf |>
  tune_grid(
    resamples = diabetes_CV_folds,
    grid = 4, 
    metrics = my_metrics)

rf_fit |>
  collect_metrics() |> 
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

rf_best_params <- select_best(rf_fit, metric ="mn_log_loss")

rf_final_wk <- finalize_workflow(rf_wkf, rf_best_params)

rf_final_fit <- rf_final_wk |>
  last_fit(diabetes_data_split, metrics = metric_set(accuracy, mn_log_loss))

rf_final_fit |> collect_metrics()
```

### Results
